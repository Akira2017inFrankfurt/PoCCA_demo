{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222dbc45",
   "metadata": {},
   "source": [
    "### 可视化函数\n",
    "- 需要安装open3d: pip3 install open3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bce1d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import random\n",
    "\n",
    "def visualize_samples(d_sample):\n",
    "    \"\"\"\n",
    "    d_sample: numpy array [10000, 3]\n",
    "    \"\"\"\n",
    "    print(\"Points in downsample set: \", len(d_sample))\n",
    "    source = o3d.geometry.PointCloud()\n",
    "    source.points = o3d.utility.Vector3dVector(d_sample)\n",
    "    color = [102.0 / 255.0 ,111.0 / 255.0, 142.0 / 255.0]\n",
    "    source.paint_uniform_color(color)\n",
    "    o3d.visualization.draw_geometries([source])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8408aa9",
   "metadata": {},
   "source": [
    "### 提取并可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5379a3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in downsample set:  10000\n"
     ]
    }
   ],
   "source": [
    "# 展示原始点云\n",
    "root = r'/home/haruki/下载/modelnet40_normal_resampled/chair/chair_0039.txt'\n",
    "point_set = np.loadtxt(root, delimiter=',').astype(np.float32)[:, 0:3]\n",
    "visualize_samples(point_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3dd95",
   "metadata": {},
   "source": [
    "### 保存点云txt文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c82081df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "def save_txt(d_sample):\n",
    "    \"\"\"\n",
    "    d_sample: sampled point set\n",
    "    可以根据运行的本地时间直接在当前文件夹下面创建并保存一个新txt文件，稍后根据自己需要重新命名\n",
    "    \"\"\"\n",
    "    now = time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime())\n",
    "    now_txt = now + '.txt'\n",
    "    current_file_path = os.getcwd()\n",
    "    txt_file_name = os.path.join(current_file_path, now_txt)\n",
    "    np.savetxt(txt_file_name, d_sample, fmt='%.6e', delimiter=',')\n",
    "    print(\"Text Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6875e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Saved!\n"
     ]
    }
   ],
   "source": [
    "save_txt(point_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87b3ab0",
   "metadata": {},
   "source": [
    "### 保存点云截图png文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a0dc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_screen_filename():\n",
    "    now = time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime())\n",
    "    now_png = now + '.png'\n",
    "    current_file_path = os.getcwd()\n",
    "    png_file_name = os.path.join(current_file_path, now_png)\n",
    "    return png_file_name\n",
    "\n",
    "\n",
    "def custom_draw_geometry_with_key_callback(pcd):\n",
    "    def close_window(vis):\n",
    "        vis.close()\n",
    "        return False\n",
    "\n",
    "    def rotate_view(vis):\n",
    "        ctr = vis.get_view_control()\n",
    "        # every step how much to rotate\n",
    "        # x -800\n",
    "        # y 100\n",
    "        ctr.rotate(-800.0, 100.0)\n",
    "        return False\n",
    "\n",
    "    def save_capture_screen_image(vis):\n",
    "        vis.capture_screen_image(get_screen_filename())\n",
    "        return False\n",
    "\n",
    "    key_to_callback = {}\n",
    "    key_to_callback[ord(\"C\")] = close_window\n",
    "    key_to_callback[ord(\"R\")] = rotate_view\n",
    "    key_to_callback[ord(\"S\")] = save_capture_screen_image\n",
    "\n",
    "    o3d.visualization.draw_geometries_with_key_callbacks([pcd], key_to_callback)\n",
    "    \n",
    "    \n",
    "def visualization(point_set):\n",
    "    source = o3d.geometry.PointCloud()\n",
    "    source.points = o3d.utility.Vector3dVector(point_set)\n",
    "    color = [102.0 / 255.0, 111.0 / 255.0, 142.0 / 255.0]\n",
    "    source.paint_uniform_color(color)\n",
    "    custom_draw_geometry_with_key_callback(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b9eb4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(point_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e6c8e",
   "metadata": {},
   "source": [
    "- 感觉可以的： chair_0005,chair_0020,chair_0039\n",
    "- 最后选择0039，感觉这个比较好\n",
    "- 上传chair_0039.txt到GitHub项目中的data文件夹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59102f",
   "metadata": {},
   "source": [
    "### Subsample: FPS算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cdafab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fps(original, npoints):\n",
    "    \"\"\"\n",
    "    original: numpy array [10000, 3]\n",
    "    npoints: output point number\n",
    "    return: downsampled point set [npoints, 3]\n",
    "    \"\"\"\n",
    "    center_xyz = np.sum(original, 0)\n",
    "    center_xyz = center_xyz / len(original)\n",
    "    dist = np.sum((original - center_xyz) ** 2, 1)\n",
    "    farthest = np.argmax(dist)\n",
    "    distance = np.ones(len(original)) * 1e10\n",
    "    target_index = np.zeros(npoints, dtype=np.int32)\n",
    "\n",
    "    for i in range(npoints):\n",
    "        target_index[i] = farthest\n",
    "        target_point_xyz = original[target_index[i], :]\n",
    "        \n",
    "        dist = np.sum((original - target_point_xyz) ** 2, 1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = np.argmax(distance)\n",
    "    \n",
    "    return original[target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "656114eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in downsample set:  1024\n"
     ]
    }
   ],
   "source": [
    "# 展示下采样之后的点云\n",
    "downsample_fps = fps(point_set, 1024)\n",
    "visualize_samples(downsample_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4e2e429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(downsample_fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45995862",
   "metadata": {},
   "source": [
    "### Augmentation: PointWOLF算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17925436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class PointWOLF(object):\n",
    "    def __init__(self, w_sigma):\n",
    "        self.num_anchor = 4\n",
    "        self.sample_type = 'fps'  # 'random'\n",
    "        self.sigma = w_sigma\n",
    "\n",
    "        self.R_range = (-abs(10), abs(10))\n",
    "        self.S_range = (1., 3)\n",
    "        self.T_range = (-abs(0.25), abs(0.25))\n",
    "\n",
    "    def __call__(self, pos):\n",
    "        M = self.num_anchor  # (Mx3)\n",
    "        N, _ = pos.shape  # (N)\n",
    "\n",
    "        if self.sample_type == 'random':\n",
    "            idx = np.random.choice(N, M)  # (M)\n",
    "        elif self.sample_type == 'fps':\n",
    "            idx = self.fps(pos, M)  # (M)\n",
    "\n",
    "        pos_anchor = pos[idx]  # (M,3), anchor point\n",
    "\n",
    "        pos_repeat = np.expand_dims(pos, 0).repeat(M, axis=0)  # (M,N,3)\n",
    "        pos_normalize = np.zeros_like(pos_repeat, dtype=pos.dtype)  # (M,N,3)\n",
    "        pos_normalize = pos_repeat - pos_anchor.reshape(M, -1, 3)\n",
    "\n",
    "        # Local transformation at anchor point\n",
    "        pos_transformed = self.local_transformaton(pos_normalize)  # (M,N,3)\n",
    "\n",
    "        # Move to origin space\n",
    "        pos_transformed = pos_transformed + pos_anchor.reshape(M, -1, 3)  # (M,N,3)\n",
    "\n",
    "        pos_new = self.kernel_regression(pos, pos_anchor, pos_transformed)\n",
    "        pos_new = self.normalize(pos_new)\n",
    "\n",
    "        return pos_new.astype('float32')\n",
    "\n",
    "    def kernel_regression(self, pos, pos_anchor, pos_transformed):\n",
    "        M, N, _ = pos_transformed.shape\n",
    "\n",
    "        # Distance between anchor points & entire points\n",
    "        sub = np.expand_dims(pos_anchor, 1).repeat(N, axis=1) - np.expand_dims(pos, 0).repeat(M, axis=0)  # (M,N,3), d\n",
    "\n",
    "        project_axis = self.get_random_axis(1)\n",
    "\n",
    "        projection = np.expand_dims(project_axis, axis=1) * np.eye(3)  # (1,3,3)\n",
    "\n",
    "        # Project distance\n",
    "        sub = sub @ projection  # (M,N,3)\n",
    "        sub = np.sqrt(((sub) ** 2).sum(2))  # (M,N)\n",
    "\n",
    "        # Kernel regression\n",
    "        weight = np.exp(-0.5 * (sub ** 2) / (self.sigma ** 2))  # (M,N)\n",
    "        pos_new = (np.expand_dims(weight, 2).repeat(3, axis=-1) * pos_transformed).sum(0)  # (N,3)\n",
    "        pos_new = (pos_new / weight.sum(0, keepdims=True).T)  # normalize by weight\n",
    "        return pos_new\n",
    "\n",
    "    def fps(self, pos, npoint):\n",
    "        N, _ = pos.shape\n",
    "        centroids = np.zeros(npoint, dtype=np.int_)  # (M)\n",
    "        distance = np.ones(N, dtype=np.float64) * 1e10  # (N)\n",
    "        farthest = np.random.randint(0, N, (1,), dtype=np.int_)\n",
    "        for i in range(npoint):\n",
    "            centroids[i] = farthest\n",
    "            centroid = pos[farthest, :]\n",
    "            dist = ((pos - centroid) ** 2).sum(-1)\n",
    "            mask = dist < distance\n",
    "            distance[mask] = dist[mask]\n",
    "            farthest = distance.argmax()\n",
    "        return centroids\n",
    "\n",
    "    def local_transformaton(self, pos_normalize):\n",
    "        M, N, _ = pos_normalize.shape\n",
    "        transformation_dropout = np.random.binomial(1, 0.5, (M, 3))  # (M,3)\n",
    "        transformation_axis = self.get_random_axis(M)  # (M,3)\n",
    "\n",
    "        degree = np.pi * np.random.uniform(*self.R_range, size=(M, 3)) / 180.0 * transformation_dropout[:,\n",
    "                                                                                 0:1]  # (M,3), sampling from (-R_range, R_range)\n",
    "\n",
    "        scale = np.random.uniform(*self.S_range, size=(M, 3)) * transformation_dropout[:,\n",
    "                                                                1:2]  # (M,3), sampling from (1, S_range)\n",
    "        scale = scale * transformation_axis\n",
    "        scale = scale + 1 * (scale == 0)  # Scaling factor must be larger than 1\n",
    "\n",
    "        trl = np.random.uniform(*self.T_range, size=(M, 3)) * transformation_dropout[:,\n",
    "                                                              2:3]  # (M,3), sampling from (1, T_range)\n",
    "        trl = trl * transformation_axis\n",
    "\n",
    "        # Scaling Matrix\n",
    "        S = np.expand_dims(scale, axis=1) * np.eye(3)  # scailing factor to diagonal matrix (M,3) -> (M,3,3)\n",
    "        # Rotation Matrix\n",
    "        sin = np.sin(degree)\n",
    "        cos = np.cos(degree)\n",
    "        sx, sy, sz = sin[:, 0], sin[:, 1], sin[:, 2]\n",
    "        cx, cy, cz = cos[:, 0], cos[:, 1], cos[:, 2]\n",
    "        R = np.stack([cz * cy, cz * sy * sx - sz * cx, cz * sy * cx + sz * sx,\n",
    "                      sz * cy, sz * sy * sx + cz * cy, sz * sy * cx - cz * sx,\n",
    "                      -sy, cy * sx, cy * cx], axis=1).reshape(M, 3, 3)\n",
    "\n",
    "        pos_normalize = pos_normalize @ R @ S + trl.reshape(M, 1, 3)\n",
    "        return pos_normalize\n",
    "\n",
    "    def get_random_axis(self, n_axis):\n",
    "        axis = np.random.randint(1, 8, (\n",
    "            n_axis))  # 1(001):z, 2(010):y, 3(011):yz, 4(100):x, 5(101):xz, 6(110):xy, 7(111):xyz\n",
    "        m = 3\n",
    "        axis = ((axis[:, None] & (1 << np.arange(m))) > 0).astype(int)\n",
    "        return axis\n",
    "\n",
    "    def normalize(self, pos):\n",
    "        pos = pos - pos.mean(axis=-2, keepdims=True)\n",
    "        scale = (1 / np.sqrt((pos ** 2).sum(1)).max()) * 0.999999\n",
    "        pos = scale * pos\n",
    "        return pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7c1b6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化点云函数\n",
    "# 不需要修改参数，只是重新执行这个函数就可以得到不同的增强结果\n",
    "augment_func = PointWOLF(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e16dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成augmentation\n",
    "aug_point_set = augment_func(point_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b45eecb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in downsample set:  10000\n"
     ]
    }
   ],
   "source": [
    "# 可视化经过增强处理的点云\n",
    "visualize_samples(aug_point_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36d57247",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(aug_point_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3816fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比原始点云的样子\n",
    "visualize_samples(point_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c02d1f2",
   "metadata": {},
   "source": [
    "### Crop_Method 1/3  Slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef72a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 slices per axis， 40% points of one point cloud\n",
    "def get_index(index_slice, ration_per_slice, overlap_ration, num_all_points):\n",
    "    # index_slice = 0, 1, 2\n",
    "    start_index = index_slice * (ration_per_slice - overlap_ration) * num_all_points\n",
    "    end_index = start_index + ration_per_slice * num_all_points\n",
    "    return int(start_index), int(end_index)\n",
    "\n",
    "def get_slice(point_set, npoints, xyz_dim, index_slice):\n",
    "    # xyz_dim: 0, 1, 2 for x, y, z\n",
    "    axis = 'x'\n",
    "    if xyz_dim == 1:\n",
    "        axis = 'y'\n",
    "    elif xyz_dim == 2:\n",
    "        axis = 'z'\n",
    "    print(f\"这个是沿着{axis}轴来切割的，第{index_slice}个slice.\")\n",
    "    \n",
    "    start_index, end_index = get_index(index_slice, 0.4, 0.1, len(point_set))\n",
    "    big_patch_index = np.argsort(point_set, axis=0)[start_index: end_index, xyz_dim]\n",
    "    big_patch = point_set[big_patch_index]\n",
    "    random.shuffle(big_patch)\n",
    "    # 返回fps后的值，fps前的值\n",
    "    return (fps(big_patch, npoints), big_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e1aa6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这个是沿着x轴来切割的，第0个slice.\n"
     ]
    }
   ],
   "source": [
    "after_fps_slice, direct_slice = get_slice(point_set, 1024, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e4c8e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in downsample set:  1024\n"
     ]
    }
   ],
   "source": [
    "# fps之后的点云可视化\n",
    "visualize_samples(after_fps_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "24f09a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(after_fps_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b213de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in downsample set:  4000\n"
     ]
    }
   ],
   "source": [
    "# fps之前的点云\n",
    "visualize_samples(direct_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7a2500fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(direct_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3d78dd",
   "metadata": {},
   "source": [
    "### Crop_Method 2/3 Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "314ca202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_center():\n",
    "    \"\"\"随机生成一个cube中心点\"\"\"\n",
    "    u = np.random.uniform(-1.0, 1.0)\n",
    "    theta = 2 * np.pi * np.random.uniform(0.0, 2)\n",
    "    \n",
    "    x = np.power((1 - u * u), 1/2) * np.cos(theta)\n",
    "    x = np.abs(x)\n",
    "    x = np.random.uniform(-x, x)\n",
    "    y = np.power((1 - u * u), 1/2) * np.sin(theta)\n",
    "    y = np.abs(y)\n",
    "    y = np.random.uniform(-y, y)\n",
    "    z = u\n",
    "    return (x, y, z)\n",
    "\n",
    "\n",
    "def point_in_cube(point_xyz, center_xyz, side_length):\n",
    "    \"\"\"判断一个点是否在cube内部\"\"\"\n",
    "    flag = True\n",
    "    for i in range(0, len(point_xyz)):\n",
    "        if abs(point_xyz[i] - center_xyz[i]) >= (side_length / 2):\n",
    "            flag = False\n",
    "            break\n",
    "    return flag\n",
    "\n",
    "\n",
    "def get_1_cube(point_set, center_xyz, side_length, npoints=1024):\n",
    "    \"\"\"从单个点云中，根据1个中心点找到1个cube\"\"\"\n",
    "    output_samples = []\n",
    "    for i in range(0, len(point_set)):\n",
    "        if point_in_cube(point_set[i], center_xyz, side_length):\n",
    "            output_samples.append(i)\n",
    "    samples = point_set[output_samples]\n",
    "    \n",
    "    if len(output_samples) > npoints:\n",
    "        result = fps(samples, npoints)\n",
    "        return result\n",
    "    else:\n",
    "        return get_1_cube(point_set, center_xyz, side_length + 0.2, npoints)\n",
    "    \n",
    "    \n",
    "def get_cubes(point_set, num_cube=8, side_length=0.5, npoints=1024):\n",
    "    \"\"\"从单个点云中，根据8个中心点找到8个cube\"\"\"\n",
    "    result = np.ones((num_cube, npoints, 3))\n",
    "    centers = []  # record 8 cube centers\n",
    "    for i in range(0, num_cube):\n",
    "        center = get_random_center()\n",
    "        centers.append(center)\n",
    "        result[i] = get_1_cube(point_set, center, side_length, npoints)\n",
    "    return result, centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "492ec9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "cubes, centers = get_cubes(point_set)\n",
    "print(cubes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a85d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in downsample set:  1024\n"
     ]
    }
   ],
   "source": [
    "# 查看其中一个cube\n",
    "random_choice = 5\n",
    "chose_1_cube = cubes[random_choice, :, :]\n",
    "visualize_samples(chose_1_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "15fc3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(chose_1_cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd61f2",
   "metadata": {},
   "source": [
    "### Crop_Method 3/3 KNN(Sphere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ece09b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S, [K]]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, [K], C]\n",
    "    \"\"\"\n",
    "    raw_size = idx.size()\n",
    "    idx = idx.reshape(raw_size[0], -1)\n",
    "    res = torch.gather(points, 1, idx[..., None].expand(-1, -1, points.size(-1)))\n",
    "    return res.reshape(*raw_size, -1)\n",
    "\n",
    "\n",
    "def b_FPS(xyz, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, 3]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [B, npoint]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(B, N).to(device)* 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        distance = torch.min(distance, dist)\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids, index_points(xyz, centroids)\n",
    "\n",
    "\n",
    "def k_points(a, b, k):\n",
    "    # a: small, b: big one\n",
    "    inner = -2 * torch.matmul(a, b.transpose(2, 1))\n",
    "    aa = torch.sum(a**2, dim=2, keepdim=True)\n",
    "    bb = torch.sum(b**2, dim=2, keepdim=True)\n",
    "    pairwise_distance = -aa - inner - bb.transpose(2, 1)\n",
    "    idx = pairwise_distance.topk(k=k, dim=-1)[1]\n",
    "    return idx\n",
    "\n",
    "\n",
    "def new_k_patch(x, k=2048, n_patch=8, n_points=1024):\n",
    "    \"\"\"k = 2048, with FPS subsample method and FPS centroids\"\"\"\n",
    "    patch_centers_index, _ = b_FPS(x, n_patch)  # torch.Size([B, n_patch])\n",
    "    center_point_xyz = index_points(x, patch_centers_index)  # [B, n_patch]\n",
    "\n",
    "    idx = k_points(center_point_xyz, x, k)  # B, k, 2048\n",
    "    idx = idx.permute(0, 2, 1)  # B, k, n_patch\n",
    "\n",
    "    new_patch = torch.zeros([n_patch, x.shape[0], n_points, x.shape[-1]]).to(device)\n",
    "    for i in range(n_patch):\n",
    "        patch_idx = idx[:, :, i].reshape(x.shape[0], -1)\n",
    "        _, patch_points = b_FPS(index_points(x, patch_idx), n_points)\n",
    "        new_patch[i] = patch_points\n",
    "    new_patch = new_patch.permute(1, 0, 2, 3)   # torch.Size([B, 8, 1024, 3])\n",
    "    return new_patch\n",
    "\n",
    "\n",
    "def new_k_patch_1024(x, k=1024, n_patch=8, n_points=1024):\n",
    "    \"\"\"k=1024 without subsample method but FPS centroids\"\"\"\n",
    "    patch_centers_index, _ = b_FPS(x, n_patch)  # torch.Size([B, n_patch])\n",
    "    center_point_xyz = index_points(x, patch_centers_index)  # [B, n_patch]\n",
    "\n",
    "    idx = k_points(center_point_xyz, x, k)  # B, n_patch, 1024\n",
    "    idx = idx.permute(0, 2, 1)  # B, k, n_patch\n",
    "\n",
    "    new_patch = torch.zeros([n_patch, x.shape[0], n_points, x.shape[-1]]).to(device)\n",
    "    for i in range(n_patch):\n",
    "        patch_idx = idx[:, :, i].reshape(x.shape[0], -1)\n",
    "        patch_points = index_points(x, patch_idx)\n",
    "        new_patch[i] = patch_points\n",
    "    new_patch = new_patch.permute(1, 0, 2, 3)   # torch.Size([B, 8, 1024, 3])\n",
    "    return new_patch\n",
    "\n",
    "\n",
    "def random_k_patch_1024(x, k=1024, n_patch=8, n_points=1024):\n",
    "    \"\"\"k=1024 with random centroids\"\"\"\n",
    "    def get_random_index(point_set, num):\n",
    "        result = []\n",
    "        for i in range(point_set.shape[0]):\n",
    "            result.append(random.sample(range(0, point_set.shape[1]), num))\n",
    "        return torch.tensor(result, dtype=torch.int64).to(device)\n",
    "    \n",
    "    patch_centers_index = get_random_index(x, n_patch)  # torch.Size([B, n_patch])\n",
    "    center_point_xyz = index_points(x, patch_centers_index)  # [B, n_patch]\n",
    "\n",
    "    idx = k_points(center_point_xyz, x, k)  # B, n_patch, 1024\n",
    "    idx = idx.permute(0, 2, 1)  # B, k, n_patch\n",
    "\n",
    "    new_patch = torch.zeros([n_patch, x.shape[0], n_points, x.shape[-1]]).cuda()\n",
    "    for i in range(n_patch):\n",
    "        patch_idx = idx[:, :, i].reshape(x.shape[0], -1)\n",
    "        patch_points = index_points(x, patch_idx)\n",
    "        new_patch[i] = patch_points\n",
    "    new_patch = new_patch.permute(1, 0, 2, 3)   # torch.Size([B, 8, 1024, 3])\n",
    "    return new_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "50db61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "tensor_point_set = torch.tensor(point_set[np.newaxis, :, :]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63643993",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_2048_fps_centroids = new_k_patch(tensor_point_set)\n",
    "knn_1024_fps_centroids = new_k_patch_1024(tensor_point_set)\n",
    "knn_1024_random_centroids = new_k_patch_1024(tensor_point_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee7e4a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1024, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_2048_fps_centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c9797c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1024, 3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 维度不同需要转换\n",
    "knn_2048_fps_centroids = knn_2048_fps_centroids.reshape(8, 1024, 3)\n",
    "k1 = knn_2048_fps_centroids.cpu().numpy()\n",
    "k1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "53f2bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = k1[0]\n",
    "visualization(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f9c02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
